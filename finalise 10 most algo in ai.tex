\documentclass[12pt]{article}
\begin{document}
\textbf{\textit{NATIONAL INSTITUTE OF TECHNOLOGY, RAIPUR}}
\\
\\
\\
\begin{flushleft}
\textbf{Name- vinay kumar\\ Roll no. 20111067}\\
\end{flushleft}
\parindent 0px
\begin{footnotesize}
\begin{LARGE}
This is my first Latex document on 10 most algorithm used in AI.\\
and here is the 10 most used Algorithm in AI are\\
\end{LARGE}

\end{footnotesize}
\textbf{1} \textbf{Linear Regression}\\
   \begin{center}
    \begin{flushleft}
Linear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the independent variable.\\
\begin{center}
 $ y=mx+c $
\end{center}
    \end{flushleft}
   \end{center}
\textbf{2} \textbf{Logistic Regression\\}
\begin{center}
\begin{flushleft}
 Logistic regression estimates the probability of an event occurring, such as voted or didn’t vote, based on a given dataset of independent variables.Since the outcome is a probability, the dependent variable is bounded between 0 and 1.
\end{flushleft}
\end{center}
\textbf{3} \textbf{Linear Discriminant Analysis(LDA)}
\begin{center}
\begin{flushleft}
Linear Discriminant Analysis (LDA) is most commonly used as dimensionality reduction technique in the pre-processing step for pattern-classification and machine learning applications. The goal is to project a dataset onto a lower-dimensional space with good class-separability in order avoid overfitting (“curse of dimensionality”) and also reduce computational costs.
\end{flushleft}
\end{center}
\textbf{4} \textbf{Decision Trees}
\begin{center}
\begin{flushleft}
This is one of the most widely utilized, simplest, and efficient AI algorithms available. It's a traditional binary tree, with a Yes/No decision at each split until the model reaches the outcome node.
This approach is easy to understand, does not need data standardization, and may be used to address a variety of issues.
\end{flushleft}
\end{center}
\textbf{5} \textbf{Naive Bias}
\begin{center}
\begin{flushleft}
It is a simple, yet really strong AI algorithm for solving a variety of complex problems. It is capable of calculating two sorts of probabilities:\\
   \begin{center}
     •The probability of each class occurring.\\
     •For a standalone class with an additional x modifier, a conditional probability.\\
\end{center} 
The model is referred to as naïve since it is based on the assumption that all of the input data values are unrelated. While this is not possible in the actual world, this basic technique may be used in a variety of normalized data flows to accurately anticipate results.
\end{flushleft}
\end{center}
\textbf{6} \textbf{K-Nearest Neighbors}
\begin{center}
\begin{flushleft}
This is a basic yet effective AI algorithm that uses the entire training dataset as the representation field. The outcome value predictions are produced by searching the whole data set for K data nodes with comparable values (so-called neighbors) and determining the resulting value using the Euclidean number (which can be readily computed based on the value differences).
\end{flushleft}
\end{center}
\textbf{7} \textbf{Learning Vector Quantization}
\begin{center}
\begin{flushleft}
The single significant disadvantage of KNN is the requirement to maintain and update large datasets. Learning Vector Quantization, or LVQ, is an advanced KNN model, a neural network that defines training datasets and codifies necessary outcomes using codebook vectors. \\
As a result, the vectors are initially random, and the learning process entails changing their values to enhance prediction accuracy and consequently, locating the vectors with the most comparable values yields the best level of accuracy in predicting the end value.
\end{flushleft}
\end{center}
\textbf{8} \textbf{Support Vector Machines}
\begin{center}
\begin{flushleft}
This AI algorithm is one of the most extensively discussed among data scientists because it offers extremely robust data categorization skills. The so-called hyperplane is a line that divides data input nodes with different values, and the vectors from these points to the hyperplane can either support it (when all data instances of the same class are on the same side of the hyperplane) or defy it (when all the data instances of the same class are on opposite sides of the hyperplane) when the data point is outside the plane of its class.
\end{flushleft}
\end{center}
\textbf{9} \textbf{Random Decision Forests or Bagging}
\begin{center}
\begin{flushleft}
Random decision forests are made up of decision trees that evaluate many samples of data and aggregate the findings like putting many samples in a bag to get the most accurate output value.\\
Rather than identifying a single ideal route, many inferior paths are specified, resulting in a more precise overall outcome. If decision trees solve your problem, random forests are a variation of the method that yields even better results.
\end{flushleft}
\end{center}
\textbf{10} \textbf{Deep Neural Networks}
\begin{center}
\begin{flushleft}
DNNs are one of the most used AI and machine learning algorithms. Deep learning-based text and voice apps, deep neural networks for machine perception and OCR, as well as employing deep learning to enhance reinforced learning and robotic movement, as well as other DNN applications, have all seen substantial advances.
\end{flushleft}
\end{center}
\begin{center}
\textbf{THANK YOU}
\end{center}
\end{document}